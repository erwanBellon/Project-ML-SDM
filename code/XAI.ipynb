{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/erwanBellon/2025_ML_EES/blob/main/project/code/XAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part I: Feature map\n",
        "\n"
      ],
      "metadata": {
        "id": "pmqQkiD5osFN"
      },
      "id": "pmqQkiD5osFN"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### I.1 : setup"
      ],
      "metadata": {
        "id": "GPeQI0osxlTz"
      },
      "id": "GPeQI0osxlTz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73e0e4da",
      "metadata": {
        "id": "73e0e4da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66847228-26cf-4d22-bedf-81269500e4e7",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '2025_ML_EES'...\n",
            "remote: Enumerating objects: 1018, done.\u001b[K\n",
            "remote: Counting objects: 100% (249/249), done.\u001b[K\n",
            "remote: Compressing objects: 100% (197/197), done.\u001b[K\n",
            "remote: Total 1018 (delta 183), reused 51 (delta 51), pack-reused 769 (from 2)\u001b[K\n",
            "Receiving objects: 100% (1018/1018), 256.90 MiB | 9.61 MiB/s, done.\n",
            "Resolving deltas: 100% (669/669), done.\n",
            "Updating files: 100% (366/366), done.\n",
            "/content/2025_ML_EES\n",
            "remote: Enumerating objects: 27, done.\u001b[K\n",
            "remote: Counting objects: 100% (27/27), done.\u001b[K\n",
            "remote: Compressing objects: 100% (19/19), done.\u001b[K\n",
            "remote: Total 21 (delta 12), reused 1 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Unpacking objects: 100% (21/21), 6.52 KiB | 607.00 KiB/s, done.\n",
            "From https://github.com/erwanBellon/2025_ML_EES\n",
            "   4c8eb3f..d61330e  main       -> origin/main\n",
            "Updating 4c8eb3f..d61330e\n",
            "Fast-forward\n",
            " project/code/XAI.ipynb                            | 154 \u001b[32m++++++++++++\u001b[m\u001b[31m--------\u001b[m\n",
            " project/code/model_habitat_amount_3000_v0.ipynb   | 168 \u001b[32m+++++++++++++\u001b[m\u001b[31m---------\u001b[m\n",
            " project/outputs/{ => old}/HA_3000_bestModel.keras | Bin\n",
            " project/outputs/old/README                        |   1 \u001b[32m+\u001b[m\n",
            " 4 files changed, 194 insertions(+), 129 deletions(-)\n",
            " rename project/outputs/{ => old}/HA_3000_bestModel.keras (100%)\n",
            " create mode 100644 project/outputs/old/README\n",
            "/content/2025_ML_EES/project/code\n",
            "Current working directory: /content/2025_ML_EES/project/code\n",
            "Outputs will be saved to: /content/2025_ML_EES/project/outputs\n",
            "No GPU detected. CNNs can be slow without GPU.\n",
            "Requirement already satisfied: rasterio in /usr/local/lib/python3.12/dist-packages (1.4.3)\n",
            "Requirement already satisfied: affine in /usr/local/lib/python3.12/dist-packages (from rasterio) (2.4.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.12/dist-packages (from rasterio) (25.4.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from rasterio) (2025.11.12)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.12/dist-packages (from rasterio) (8.3.1)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.12/dist-packages (from rasterio) (0.7.2)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.12/dist-packages (from rasterio) (2.0.2)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.12/dist-packages (from rasterio) (1.1.1.2)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from rasterio) (3.2.5)\n",
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ]
        }
      ],
      "source": [
        "# @title\n",
        "\n",
        "# Python ≥3.5 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# Is this notebook running on Colab or Kaggle?\n",
        "IS_COLAB = \"google.colab\" in sys.modules\n",
        "IS_KAGGLE = \"kaggle_secrets\" in sys.modules\n",
        "\n",
        "# Cloning repo or fetch latest changes and path management\n",
        "!git clone https://github.com/erwanBellon/2025_ML_EES.git\n",
        "%cd /content/2025_ML_EES\n",
        "!git pull\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Move into the project directory\n",
        "%cd /content/2025_ML_EES/project/code\n",
        "print(\"Current working directory:\", Path.cwd())\n",
        "\n",
        "# Define main project dir and outputs\n",
        "PROJECT_ROOT_DIR = Path.cwd().parent       # -> /content/2025_ML_EES/project\n",
        "OUTPUTS_PATH = PROJECT_ROOT_DIR / \"outputs\"\n",
        "OUTPUTS_PATH.mkdir(parents=True, exist_ok=True)\n",
        "print(\"Outputs will be saved to:\", OUTPUTS_PATH)\n",
        "\n",
        "# Scikit-Learn ≥0.20 is required\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "# TensorFlow ≥2.0 is required\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, Model, Input\n",
        "assert tf.__version__ >= \"2.0\"\n",
        "\n",
        "if not tf.config.list_physical_devices('GPU'):\n",
        "    print(\"No GPU detected. CNNs can be slow without GPU.\")\n",
        "\n",
        "# Common imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "!pip install rasterio\n",
        "import rasterio\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# To make notebook reproducible\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# For plots\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Load Tensorboard\n",
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(Path.cwd())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwFyFqHTiiaJ",
        "outputId": "41a80ac8-8425-43f9-bd19-b7dd481c5293"
      },
      "id": "TwFyFqHTiiaJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/2025_ML_EES/project/code\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## I.2 Load the model using a CNN-ANN framework"
      ],
      "metadata": {
        "id": "btSf40XCpxO0"
      },
      "id": "btSf40XCpxO0"
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# Path to your saved model\n",
        "model_path = Path.cwd() /\"../outputs/cnn_bestModel.keras\"\n",
        "\n",
        "# Load model\n",
        "model = load_model(model_path)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 950
        },
        "id": "B68inGVTqAGs",
        "outputId": "fa004978-3e2a-4a6a-88ad-61523e547e39",
        "cellView": "form"
      },
      "id": "B68inGVTqAGs",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ image_input         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ random_flip         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ image_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mRandomFlip\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ random_zoom         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ random_flip[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mRandomZoom\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ random_translation  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ random_zoom[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mRandomTranslation\u001b[0m) │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m,    │        \u001b[38;5;34m320\u001b[0m │ random_translati… │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m,    │      \u001b[38;5;34m9,248\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m,    │     \u001b[38;5;34m18,496\u001b[0m │ max_pooling2d[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ table_input         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3136\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_1[\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │         \u001b[38;5;34m48\u001b[0m │ table_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │    \u001b[38;5;34m100,384\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │        \u001b[38;5;34m136\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m1,312\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │        \u001b[38;5;34m264\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m9\u001b[0m │ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ image_input         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ random_flip         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ image_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RandomFlip</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ random_zoom         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ random_flip[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RandomZoom</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ random_translation  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ random_zoom[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RandomTranslation</span>) │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │ random_translati… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │ max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ table_input         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3136</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span> │ table_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │    <span style=\"color: #00af00; text-decoration-color: #00af00\">100,384</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,312</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">264</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m390,653\u001b[0m (1.49 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">390,653</span> (1.49 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m130,217\u001b[0m (508.66 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">130,217</span> (508.66 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m260,436\u001b[0m (1017.33 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">260,436</span> (1017.33 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### I.3 Load image data (and table input) and preprocess the datas\n"
      ],
      "metadata": {
        "id": "yaC6eelXnFMl"
      },
      "id": "yaC6eelXnFMl"
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# --- Load images ---\n",
        "presences_path = Path(\"../data/cropped_landcover/presences\")\n",
        "absences_path = Path(\"../data/cropped_landcover/absences\")\n",
        "\n",
        "def load_images_from_folder(folder):\n",
        "    tif_files = list(folder.glob(\"*.tif\"))\n",
        "    images = []\n",
        "    image_indices = []\n",
        "    for tif in tif_files:\n",
        "        with rasterio.open(tif) as src:\n",
        "            img = src.read()\n",
        "            img = np.transpose(img, (1,2,0))\n",
        "            images.append(img.astype(np.float32))\n",
        "        # Extract the line index from the filename (assuming `crop_3000_118.tif`)\n",
        "        idx = int(tif.stem.split(\"_\")[-1])\n",
        "        image_indices.append(idx)\n",
        "    return np.array(images), np.array(image_indices)\n",
        "\n",
        "images_pres, indices_pres = load_images_from_folder(presences_path)\n",
        "images_abs, indices_abs = load_images_from_folder(absences_path)\n",
        "print(f\"Presences: {images_pres.shape}, Absences: {images_abs.shape}\")\n",
        "\n",
        "# Build dataset & labels\n",
        "X = np.concatenate([images_pres, images_abs], axis=0)\n",
        "y = np.concatenate([np.ones(len(images_pres)), np.zeros(len(images_abs))], axis=0).astype(np.int32)\n",
        "image_indices = np.concatenate([indices_pres, indices_abs], axis=0)  # all image row indices\n",
        "\n",
        "# --- Load table data ---\n",
        "rds_path = Path(\"../data/Table_preds/function_3_100.rds\")\n",
        "!pip install pyreadr\n",
        "import pyreadr\n",
        "result = pyreadr.read_r(rds_path)\n",
        "table_df = result[None]  # get DataFrame\n",
        "\n",
        "# Select only the rows corresponding to actual images\n",
        "table_features_all = table_df[['MAP','MAT']].astype(float)\n",
        "table_features = table_features_all.iloc[image_indices].reset_index(drop=True)\n",
        "\n",
        "# Normalize\n",
        "table_features = (table_features - table_features.min()) / (table_features.max() - table_features.min())\n",
        "table_features = table_features.to_numpy(dtype=np.float32)\n",
        "\n",
        "X_train, X_temp, table_train, table_temp, y_train, y_temp = train_test_split(\n",
        "    X, table_features, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "X_valid, X_test, table_valid, table_test, y_valid, y_test = train_test_split(\n",
        "    X_temp, table_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "qXmsSnh9nOyf",
        "outputId": "f1715ba3-3758-4412-a7e7-ecc0332758f0"
      },
      "id": "qXmsSnh9nOyf",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Presences: (117, 30, 30, 1), Absences: (200, 30, 30, 1)\n",
            "Requirement already satisfied: pyreadr in /usr/local/lib/python3.12/dist-packages (0.5.4)\n",
            "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from pyreadr) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2.0->pyreadr) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2.0->pyreadr) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2.0->pyreadr) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2.0->pyreadr) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.2.0->pyreadr) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "train_ds = tf.data.Dataset.from_tensor_slices(((X_train, table_train), y_train))\n",
        "valid_ds = tf.data.Dataset.from_tensor_slices(((X_valid, table_valid), y_valid))\n",
        "test_ds  = tf.data.Dataset.from_tensor_slices(((X_test, table_test), y_test))\n",
        "\n",
        "\n",
        "# Add `.name` attribute like TFDS\n",
        "train_ds.name = \"Training\"\n",
        "valid_ds.name = \"Validation\"\n",
        "test_ds.name  = \"Test\""
      ],
      "metadata": {
        "cellView": "form",
        "id": "ugWPu3TGnagb"
      },
      "id": "ugWPu3TGnagb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "def preprocess_multi_inputs(inputs, label):\n",
        "    image, table = inputs\n",
        "    # Convert image to float32 and add channel dimension if needed\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    # Replace Nan (non-forest) with 0s\n",
        "    image = tf.where(tf.math.is_nan(image), 0.0, image)\n",
        "\n",
        "    if len(image.shape) == 3:  # (H,W,C) or (H,W)\n",
        "        image = tf.expand_dims(image, -1)  # ensures (H,W,1)\n",
        "    # Table should already be (batch_size, 2) after batching\n",
        "    table = tf.cast(table, tf.float32)\n",
        "    label = tf.cast(label, tf.float32)\n",
        "    return (image, table), label"
      ],
      "metadata": {
        "cellView": "form",
        "id": "kwMhv9mEnes2"
      },
      "id": "kwMhv9mEnes2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "train_ds = (\n",
        "    tf.data.Dataset.from_tensor_slices(((X_train, table_train), y_train))\n",
        "      .shuffle(1000, reshuffle_each_iteration=True)   # <--- SHUFFLE HERE\n",
        "      .map(preprocess_multi_inputs, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "      .prefetch(tf.data.AUTOTUNE)\n",
        ")\n",
        "valid_ds = (\n",
        "    tf.data.Dataset.from_tensor_slices(((X_valid, table_valid), y_valid))\n",
        "      .map(preprocess_multi_inputs, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "      .prefetch(tf.data.AUTOTUNE)\n",
        ")\n",
        "\n",
        "test_ds = (\n",
        "    tf.data.Dataset.from_tensor_slices(((X_test, table_test), y_test))\n",
        "      .map(preprocess_multi_inputs, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "      .prefetch(tf.data.AUTOTUNE)\n",
        ")\n",
        "\n",
        "# Add `.name` attribute like TFDS\n",
        "train_ds.name = \"Training\"\n",
        "valid_ds.name = \"Validation\"\n",
        "test_ds.name  = \"Test\"\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "d4zlOiMCnhCZ"
      },
      "id": "d4zlOiMCnhCZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the test dataset and prepare 15 sample images\n"
      ],
      "metadata": {
        "id": "6nV_tmChrIei"
      },
      "id": "6nV_tmChrIei"
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "sample_images = []\n",
        "sample_tables = []\n",
        "\n",
        "for (img, tab), label in test_ds.take(15):  # to get single samples\n",
        "    # Image preprocessing\n",
        "    img = tf.cast(img, tf.float32)\n",
        "    img = tf.where(tf.math.is_nan(img), 0.0, img)\n",
        "    if len(img.shape) == 2:  # (H,W)\n",
        "        img = tf.expand_dims(img, -1)  # (H,W,1)\n",
        "    sample_images.append(img.numpy())\n",
        "\n",
        "    # Table preprocessing\n",
        "    tab = tf.cast(tab, tf.float32)\n",
        "    sample_tables.append(tab.numpy())\n",
        "\n",
        "# Convert to numpy arrays with batch dimension\n",
        "sample_images = np.stack(sample_images)\n",
        "sample_tables = np.stack(sample_tables)\n",
        "\n",
        "print(\"Sample images shape:\", sample_images.shape)   # (5,H,W,C)\n",
        "print(\"Sample tables shape:\", sample_tables.shape)   # (5,n_features)\n",
        "print(\"Min/Max values:\", img.numpy().min(), img.numpy().max())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "-487qDN7rF1l",
        "outputId": "b1048844-2b87-4201-b583-411d27a44233"
      },
      "id": "-487qDN7rF1l",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample images shape: (15, 30, 30, 1, 1)\n",
            "Sample tables shape: (15, 2)\n",
            "Min/Max values: 0.0 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## I.4. Looking at the feature maps"
      ],
      "metadata": {
        "id": "PIRpC-JEmOTN"
      },
      "id": "PIRpC-JEmOTN"
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# Print all layers with their output shapes\n",
        "for i, layer in enumerate(model.layers):\n",
        "    try:\n",
        "        shape = layer.output.shape\n",
        "    except AttributeError:\n",
        "        shape = \"N/A\"  # For InputLayer or unusual layers\n",
        "    print(i, layer.name, shape, type(layer))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "IEXMrSNLmUpK",
        "outputId": "22d745bb-b9ca-4a7c-cf06-990c281270f2"
      },
      "id": "IEXMrSNLmUpK",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 image_input (None, 30, 30, 1) <class 'keras.src.layers.core.input_layer.InputLayer'>\n",
            "1 random_flip (None, 30, 30, 1) <class 'keras.src.layers.preprocessing.image_preprocessing.random_flip.RandomFlip'>\n",
            "2 random_zoom (None, 30, 30, 1) <class 'keras.src.layers.preprocessing.image_preprocessing.random_zoom.RandomZoom'>\n",
            "3 random_translation (None, 30, 30, 1) <class 'keras.src.layers.preprocessing.image_preprocessing.random_translation.RandomTranslation'>\n",
            "4 conv2d (None, 30, 30, 32) <class 'keras.src.layers.convolutional.conv2d.Conv2D'>\n",
            "5 conv2d_1 (None, 30, 30, 32) <class 'keras.src.layers.convolutional.conv2d.Conv2D'>\n",
            "6 max_pooling2d (None, 15, 15, 32) <class 'keras.src.layers.pooling.max_pooling2d.MaxPooling2D'>\n",
            "7 conv2d_2 (None, 15, 15, 64) <class 'keras.src.layers.convolutional.conv2d.Conv2D'>\n",
            "8 max_pooling2d_1 (None, 7, 7, 64) <class 'keras.src.layers.pooling.max_pooling2d.MaxPooling2D'>\n",
            "9 table_input (None, 2) <class 'keras.src.layers.core.input_layer.InputLayer'>\n",
            "10 flatten (None, 3136) <class 'keras.src.layers.reshaping.flatten.Flatten'>\n",
            "11 dense_1 (None, 16) <class 'keras.src.layers.core.dense.Dense'>\n",
            "12 dense (None, 32) <class 'keras.src.layers.core.dense.Dense'>\n",
            "13 dense_2 (None, 8) <class 'keras.src.layers.core.dense.Dense'>\n",
            "14 concatenate (None, 40) <class 'keras.src.layers.merging.concatenate.Concatenate'>\n",
            "15 dense_3 (None, 32) <class 'keras.src.layers.core.dense.Dense'>\n",
            "16 dropout (None, 32) <class 'keras.src.layers.regularization.dropout.Dropout'>\n",
            "17 dense_4 (None, 8) <class 'keras.src.layers.core.dense.Dense'>\n",
            "18 dense_5 (None, 1) <class 'keras.src.layers.core.dense.Dense'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Select the part of the model that outputs features\n",
        "\n",
        "I'm interested at looking at the feature map of the last convolution layer (conv2d_2). So I extract it and output its feature (sub_model)"
      ],
      "metadata": {
        "id": "etxhL-aqPvhn"
      },
      "id": "etxhL-aqPvhn"
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "\n",
        "# Get the conv layer of interest\n",
        "conv_layer = model.get_layer(\"conv2d_2\")\n",
        "print(\"conv layer:\",conv_layer.name, conv_layer.output.shape)\n",
        "\n",
        "# Build sub-model from original model ---\n",
        "# Input = both image and table, output = last conv layer\n",
        "feature_map_model = Model(inputs=model.inputs, outputs=conv_layer.output)\n",
        "\n",
        "# Prepare 15 samples from test dataset ---\n",
        "sample_images = []\n",
        "sample_tables = []\n",
        "\n",
        "for (img, tab), label in test_ds.take(15):  # get single samples\n",
        "    # Image preprocessing\n",
        "    img = tf.cast(img, tf.float32)\n",
        "    img = tf.where(tf.math.is_nan(img), 0.0, img)\n",
        "    if len(img.shape) == 2:  # (H,W)\n",
        "        img = tf.expand_dims(img, -1)  # (H,W,1)\n",
        "    sample_images.append(img.numpy())\n",
        "\n",
        "    # Table preprocessing\n",
        "    tab = tf.cast(tab, tf.float32)\n",
        "    sample_tables.append(tab.numpy())\n",
        "\n",
        "# Convert to numpy arrays with batch dimension\n",
        "sample_images = np.stack(sample_images)\n",
        "sample_tables = np.stack(sample_tables)\n",
        "\n",
        "print(\"Sample images shape:\", sample_images.shape)   # (15,H,W,C)\n",
        "print(\"Sample tables shape:\", sample_tables.shape)   # (15,n_features)\n",
        "print(\"Min/Max values:\", img.numpy().min(), img.numpy().max())\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfJUcDqBraOb",
        "outputId": "fe4bfc16-e9ae-45d0-9db8-b51960331f42"
      },
      "id": "dfJUcDqBraOb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conv layer: conv2d_2 (None, 15, 15, 64)\n",
            "Sample images shape: (15, 30, 30, 1, 1)\n",
            "Sample tables shape: (15, 2)\n",
            "Min/Max values: 0.0 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "\n",
        "# Custom colormap: 0 = white, 1 = dark green\n",
        "cmap_img = ListedColormap(['white', 'darkgreen'])\n",
        "\n",
        "# Map label to text\n",
        "label_map = {1: \"Presence\", 0: \"Absence\"}\n",
        "\n",
        "# Directory to save plots in Colab\n",
        "save_dir = Path(\"/content/outputs\")\n",
        "save_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "for i in range(len(sample_images)):\n",
        "    img_batch = sample_images[i:i+1]   # shape (1,H,W,C)\n",
        "    tab_batch = sample_tables[i:i+1]   # shape (1,n_features)\n",
        "    label = y_test[i]                   # true label\n",
        "\n",
        "    # --- Get model prediction ---\n",
        "    pred_prob = model.predict([img_batch, tab_batch], verbose=0)[0,0]\n",
        "\n",
        "    # Predict feature maps\n",
        "    feature_maps = feature_map_model.predict([img_batch, tab_batch], verbose=0)\n",
        "\n",
        "    # Compute mean activation per filter\n",
        "    mean_activation = feature_maps.mean(axis=(1,2))  # shape (1, n_filters)\n",
        "\n",
        "    # Get top 3 activated filters\n",
        "    top3_idx = np.argsort(mean_activation[0])[::-1][:3]\n",
        "\n",
        "    # Plot: original + 3 feature maps\n",
        "    fig, axes = plt.subplots(1, 4, figsize=(16,5))\n",
        "\n",
        "    # Original image with predicted probability\n",
        "    axes[0].imshow(img_batch[0, :, :, 0], cmap=cmap_img, vmin=0, vmax=1)\n",
        "    axes[0].set_title(f\"Original Image\\nTrue: {label_map[label]}, Pred: {pred_prob:.3f}\")\n",
        "    axes[0].axis(\"off\")\n",
        "\n",
        "    # Feature maps\n",
        "    for j, idx in enumerate(top3_idx):\n",
        "        activation = feature_maps[0, :, :, idx]\n",
        "        activation = (activation - activation.min()) / (activation.max() - activation.min() + 1e-8)\n",
        "        im = axes[j+1].imshow(activation, cmap=\"viridis\")\n",
        "        axes[j+1].set_title(f\"Filter {idx}\")\n",
        "        axes[j+1].axis(\"off\")\n",
        "        fig.colorbar(im, ax=axes[j+1], fraction=0.046, pad=0.04)\n",
        "\n",
        "    # Save figure\n",
        "    save_path = save_dir / f\"sample_{i}_{label_map[label]}.png\"\n",
        "    plt.savefig(save_path, bbox_inches=\"tight\")\n",
        "    plt.close(fig)\n",
        "\n",
        "print(f\"Plots saved to {save_dir}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "8U1viZpFyEYq",
        "outputId": "0e1e1b37-5f8a-4f6d-bb67-bea57df6135c"
      },
      "id": "8U1viZpFyEYq",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plots saved to /content/outputs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part II: Permutation feature importance (can be ran independently of the rest)"
      ],
      "metadata": {
        "id": "waaDCZx2aOS9"
      },
      "id": "waaDCZx2aOS9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### II.1 Permutation importance for CNN-ANN"
      ],
      "metadata": {
        "id": "jha5GPhKaWm4"
      },
      "id": "jha5GPhKaWm4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Large drop in AUC after shuffling→ feature is important\n",
        "\n",
        "Small or no drop → feature is less important\n",
        "\n",
        "Negative drop → shuffling actually improved performance (can happen due to noise or correlations)"
      ],
      "metadata": {
        "id": "jQPCqB8JlLcm"
      },
      "id": "jQPCqB8JlLcm"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import rasterio\n",
        "import pyreadr\n",
        "\n",
        "#1. Load and preprocess images\n",
        "def load_images_from_folder(folder):\n",
        "    tif_files = list(folder.glob(\"*.tif\"))\n",
        "    images = []\n",
        "    image_indices = []\n",
        "    for tif in tif_files:\n",
        "        with rasterio.open(tif) as src:\n",
        "            img = src.read()\n",
        "            img = np.transpose(img, (1, 2, 0))  # (H,W,C)\n",
        "            img = img.astype(np.float32)\n",
        "            img = np.where(np.isnan(img), 0.0, img)  # replace NaNs\n",
        "            if img.ndim == 2:\n",
        "                img = np.expand_dims(img, -1)\n",
        "            images.append(img)\n",
        "        idx = int(tif.stem.split(\"_\")[-1])\n",
        "        image_indices.append(idx)\n",
        "    return np.array(images), np.array(image_indices)\n",
        "\n",
        "presences_path = Path(\"../data/cropped_landcover/presences\")\n",
        "absences_path = Path(\"../data/cropped_landcover/absences\")\n",
        "\n",
        "images_pres, indices_pres = load_images_from_folder(presences_path)\n",
        "images_abs, indices_abs = load_images_from_folder(absences_path)\n",
        "\n",
        "# Labelsadding\n",
        "X = np.concatenate([images_pres, images_abs], axis=0)\n",
        "y = np.concatenate([np.ones(len(images_pres)), np.zeros(len(images_abs))], axis=0)\n",
        "image_indices = np.concatenate([indices_pres, indices_abs], axis=0)\n",
        "\n",
        "# 2. Load table data\n",
        "rds_path = Path(\"../data/Table_preds/function_3_100.rds\")\n",
        "result = pyreadr.read_r(rds_path)\n",
        "table_df = result[None]\n",
        "\n",
        "table_features_all = table_df[['MAP','MAT']].astype(float)\n",
        "table_features = table_features_all.iloc[image_indices].reset_index(drop=True)\n",
        "# normalize\n",
        "table_features = (table_features - table_features.min()) / (table_features.max() - table_features.min())\n",
        "table_features = table_features.to_numpy(dtype=np.float32)\n",
        "\n",
        "#  3. Split dataset\n",
        "X_train, X_temp, table_train, table_temp, y_train, y_temp = train_test_split(\n",
        "    X, table_features, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "X_valid, X_test, table_valid, table_test, y_valid, y_test = train_test_split(\n",
        "    X_temp, table_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
        ")\n",
        "\n",
        "#  4. Load trained model\n",
        "model1_path = Path.cwd() / \"../outputs/cnn_bestModel.keras\"\n",
        "model1 = load_model(model1_path)\n",
        "\n",
        "\n",
        "#  5. Build inference model\n",
        "from tensorflow import keras\n",
        "\n",
        "def build_inference_model(model_trained):\n",
        "    # Inputs\n",
        "    image_input = keras.Input(shape=(30,30,1), name=\"image_input\")\n",
        "    table_input = keras.Input(shape=(2,), name=\"table_input\")\n",
        "\n",
        "    # Image branch ---\n",
        "    x = keras.layers.Conv2D(32, (3,3), activation=\"relu\", padding=\"same\", name=\"conv2d\")(image_input)\n",
        "    x = keras.layers.Conv2D(32, (3,3), activation=\"relu\", padding=\"same\", name=\"conv2d_1\")(x)\n",
        "    x = keras.layers.MaxPooling2D((2,2), name=\"max_pooling2d\")(x)\n",
        "    x = keras.layers.Conv2D(64, (3,3), activation=\"relu\", padding=\"same\", name=\"conv2d_2\")(x)\n",
        "    x = keras.layers.MaxPooling2D((2,2), name=\"max_pooling2d_1\")(x)\n",
        "    x = keras.layers.Flatten(name=\"flatten\")(x)\n",
        "    x = keras.layers.Dense(32, activation=\"sigmoid\", name=\"dense\")(x)\n",
        "\n",
        "    # Table branch\n",
        "    t = keras.layers.Dense(16, activation=\"relu\", name=\"dense_1\")(table_input)\n",
        "    t = keras.layers.Dense(8, activation=\"relu\", name=\"dense_2\")(t)\n",
        "\n",
        "    # Combined\n",
        "    merged = keras.layers.Concatenate(name=\"concatenate\")([x, t])\n",
        "    x = keras.layers.Dense(32, activation=\"relu\", name=\"dense_3\")(merged)\n",
        "    x = keras.layers.Dropout(0.4, name=\"dropout\")(x, training=False)\n",
        "    x = keras.layers.Dense(8, activation=\"relu\", name=\"dense_4\")(x)\n",
        "    output = keras.layers.Dense(1, activation=\"sigmoid\", name=\"dense_5\")(x)\n",
        "\n",
        "    inference_model = keras.Model(inputs=[image_input, table_input], outputs=output)\n",
        "\n",
        "    # Copy weights from trained model by layer name\n",
        "    for layer in inference_model.layers:\n",
        "        try:\n",
        "            trained_layer = model_trained.get_layer(layer.name)\n",
        "            layer.set_weights(trained_layer.get_weights())\n",
        "        except ValueError:\n",
        "            # Skip layers that do not exist (e.g., new Input layers)\n",
        "            pass\n",
        "\n",
        "    return inference_model\n",
        "\n",
        "\n",
        "model1_infer = build_inference_model(model1)\n",
        "\n",
        "# 6. Permutation importance\n",
        "# Shuffle the features randomly and evaluate the drop (or delta)in AUC\n",
        "def permutation_importance_model1(model, images, table, y, feature_names=None, n_repeats=20):\n",
        "\n",
        "    images = np.asarray(images, dtype=np.float32)\n",
        "    table = np.asarray(table, dtype=np.float32)\n",
        "    y = np.asarray(y, dtype=np.float32)\n",
        "\n",
        "    if feature_names is None:\n",
        "        feature_names = [f\"Feature_{i}\" for i in range(table.shape[1])]\n",
        "\n",
        "    # Baseline prediction (i.e. without shuffling)\n",
        "    base_pred = model.predict([images, table], verbose=0).flatten()\n",
        "    base_auc = roc_auc_score(y, base_pred)\n",
        "    print(f\"Baseline AUC: {base_auc:.4f}\")\n",
        "\n",
        "    importances = {}\n",
        "\n",
        "    # Table features\n",
        "    for col in range(table.shape[1]):\n",
        "        scores = []\n",
        "        for _ in range(n_repeats):\n",
        "            table_perm = table.copy()\n",
        "            np.random.shuffle(table_perm[:, col])  # shuffle this column\n",
        "            pred = model.predict([images, table_perm], verbose=0).flatten()\n",
        "            auc = roc_auc_score(y, pred)\n",
        "            scores.append(base_auc - auc)\n",
        "        importances[feature_names[col]] = np.mean(scores)\n",
        "\n",
        "\n",
        "    # Images\n",
        "    scores = []\n",
        "    for _ in range(n_repeats):\n",
        "        images_perm = images.copy()\n",
        "        np.random.shuffle(images_perm)  # shuffle entire images\n",
        "        pred = model.predict([images_perm, table], verbose=0).flatten()\n",
        "        auc = roc_auc_score(y, pred)\n",
        "        scores.append(base_auc - auc)\n",
        "    importances[\"Image\"] = np.mean(scores)\n",
        "\n",
        "    # Results print\n",
        "    print(\"\\nPermutation Feature Importances:\")\n",
        "    for key, value in sorted(importances.items(), key=lambda x: abs(x[1]), reverse=True):\n",
        "        print(f\"  {key:20s}: {value:+.4f}\")\n",
        "\n",
        "    return importances, base_auc\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#  7. Compute importance\n",
        "table_feature_names = ['MAP', 'MAT']\n",
        "importance, base_auc = permutation_importance_model1(\n",
        "    model1_infer,\n",
        "    X_test,\n",
        "    table_test,\n",
        "    y_test,\n",
        "    feature_names=table_feature_names,\n",
        "    n_repeats=5\n",
        ")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gK0oxd4VaV9C",
        "outputId": "e39d5f3d-c0a5-48a8-be05-637d1b3c7440"
      },
      "id": "gK0oxd4VaV9C",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline AUC: 0.8417\n",
            "\n",
            "Permutation Feature Importances:\n",
            "  Image               : +0.2542\n",
            "  MAT                 : +0.0300\n",
            "  MAP                 : -0.0117\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that the base AUC is slightly different from the model evaluation because I had to remove the data-augmentation layers when doing inference for feature permutation"
      ],
      "metadata": {
        "id": "mAG703mHmP8G"
      },
      "id": "mAG703mHmP8G"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### II.2 Permutation for ANN only"
      ],
      "metadata": {
        "id": "-gcByN5MahFf"
      },
      "id": "-gcByN5MahFf"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from tensorflow.keras.models import load_model\n",
        "import pyreadr\n",
        "\n",
        "# Load table data for ANN-only\n",
        "rds_path = Path(\"../data/Table_preds/function_3_100.rds\")\n",
        "result = pyreadr.read_r(rds_path)\n",
        "table_df = result[None]\n",
        "\n",
        "# Select relevant columns\n",
        "feature_df = table_df[['MAP','MAT','habitat_amount_3000']].astype(float)\n",
        "\n",
        "# Load indices for presences/absences\n",
        "presences_path = Path(\"../data/cropped_landcover/presences\")\n",
        "absences_path = Path(\"../data/cropped_landcover/absences\")\n",
        "\n",
        "def extract_indices(folder):\n",
        "    tif_files = list(folder.glob(\"*.tif\"))\n",
        "    indices = []\n",
        "    for tif in tif_files:\n",
        "        idx = int(tif.stem.split(\"_\")[-1])\n",
        "        indices.append(idx)\n",
        "    return np.array(indices)\n",
        "\n",
        "indices_pres = extract_indices(presences_path)\n",
        "indices_abs = extract_indices(absences_path)\n",
        "\n",
        "# Build label vector\n",
        "y = np.concatenate([\n",
        "    np.ones(len(indices_pres)),\n",
        "    np.zeros(len(indices_abs))\n",
        "]).astype(np.float32)\n",
        "\n",
        "# Extract corresponding rows\n",
        "feature_all = feature_df\n",
        "features = feature_all.iloc[np.concatenate([indices_pres, indices_abs])]\n",
        "features = features.reset_index(drop=True)\n",
        "\n",
        "# Normalize features 0–1\n",
        "features = (features - features.min()) / (features.max() - features.min())\n",
        "features = features.to_numpy(np.float32)\n",
        "\n",
        "# Train/valid/test split\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    features, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
        ")\n",
        "\n",
        "# Load ANN-only modeol\n",
        "model2_path = Path.cwd() / \"../outputs/HA_3000_bestModel_v2.keras\"\n",
        "model2 = load_model(model2_path)\n",
        "\n",
        "# Permutation importance for table features\n",
        "\n",
        "def permutation_importance_model2(model, table, y, feature_names=None, n_repeats=10):\n",
        "\n",
        "    table = np.asarray(table, dtype=np.float32)\n",
        "    y = np.asarray(y, dtype=np.float32)\n",
        "\n",
        "    if feature_names is None:\n",
        "        feature_names = [f\"Feature_{i}\" for i in range(table.shape[1])]\n",
        "\n",
        "    # Base prediction & AUC\n",
        "    base_pred = model.predict(table, verbose=0).flatten()\n",
        "    base_auc = roc_auc_score(y, base_pred)\n",
        "    print(f\"Baseline AUC: {base_auc:.4f}\")\n",
        "\n",
        "    importances = {}\n",
        "    for col in range(table.shape[1]):\n",
        "        scores = []\n",
        "        for _ in range(n_repeats):\n",
        "            table_perm = table.copy()\n",
        "            np.random.shuffle(table_perm[:, col])\n",
        "            pred = model.predict(table_perm, verbose=0).flatten()\n",
        "            auc = roc_auc_score(y, pred)\n",
        "            scores.append(base_auc - auc)\n",
        "        importances[feature_names[col]] = np.mean(scores)\n",
        "\n",
        "    # Result print\n",
        "    print(\"\\nPermutation importances:\")\n",
        "    for k, v in sorted(importances.items(), key=lambda x: -x[1]):\n",
        "        print(f\"{k}: {v:.4f}\")\n",
        "\n",
        "    return importances\n",
        "\n",
        "# Compute permutation importances on test set\n",
        "feature_names = ['MAP', 'MAT', 'habitat_amount_3000']\n",
        "importance = permutation_importance_model2(model2, X_test, y_test, feature_names=feature_names, n_repeats=5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYc6Z3hJjLup",
        "outputId": "734e4448-3051-4fe1-fa5c-6bad1fbcc4be"
      },
      "id": "iYc6Z3hJjLup",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline AUC: 0.6833\n",
            "\n",
            "Permutation importances:\n",
            "MAP: 0.0350\n",
            "MAT: 0.0058\n",
            "habitat_amount_3000: -0.0100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The change is baseline AUC may also be due to the dataleakage during the pre-processing of the data.."
      ],
      "metadata": {
        "id": "oT-ubhgunVSF"
      },
      "id": "oT-ubhgunVSF"
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}