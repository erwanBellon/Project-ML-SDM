{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/erwanBellon/Project-ML-SDM/blob/main/code/XAI_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part I: Feature map\n",
        "\n"
      ],
      "metadata": {
        "id": "pmqQkiD5osFN"
      },
      "id": "pmqQkiD5osFN"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### I.1 : setup"
      ],
      "metadata": {
        "id": "GPeQI0osxlTz"
      },
      "id": "GPeQI0osxlTz"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "73e0e4da",
      "metadata": {
        "id": "73e0e4da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cd96a9c-aae8-4ff7-adf4-63b6825712c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'Project-ML-SDM'...\n",
            "remote: Enumerating objects: 597, done.\u001b[K\n",
            "remote: Counting objects: 100% (147/147), done.\u001b[K\n",
            "remote: Compressing objects: 100% (127/127), done.\u001b[K\n",
            "remote: Total 597 (delta 84), reused 19 (delta 19), pack-reused 450 (from 1)\u001b[K\n",
            "Receiving objects: 100% (597/597), 20.67 MiB | 14.35 MiB/s, done.\n",
            "Resolving deltas: 100% (435/435), done.\n",
            "/content/Project-ML-SDM\n",
            "Already up to date.\n",
            "/content/Project-ML-SDM/code\n",
            "Current working directory: /content/Project-ML-SDM/code\n",
            "Outputs will be saved to: /content/Project-ML-SDM/outputs\n",
            "Requirement already satisfied: rasterio in /usr/local/lib/python3.12/dist-packages (1.5.0)\n",
            "Requirement already satisfied: affine in /usr/local/lib/python3.12/dist-packages (from rasterio) (2.4.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.12/dist-packages (from rasterio) (25.4.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from rasterio) (2026.1.4)\n",
            "Requirement already satisfied: click!=8.2.*,>=4.0 in /usr/local/lib/python3.12/dist-packages (from rasterio) (8.3.1)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.12/dist-packages (from rasterio) (0.7.2)\n",
            "Requirement already satisfied: numpy>=2 in /usr/local/lib/python3.12/dist-packages (from rasterio) (2.0.2)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from rasterio) (3.3.2)\n"
          ]
        }
      ],
      "source": [
        "# @title\n",
        "#Python ≥3.5 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# Is this notebook running on Colab or Kaggle?\n",
        "IS_COLAB = \"google.colab\" in sys.modules\n",
        "IS_KAGGLE = \"kaggle_secrets\" in sys.modules\n",
        "\n",
        "# Cloning repo or fetch latest changes and path management\n",
        "%cd /content\n",
        "!rm -rf Project-ML-SDM\n",
        "!git clone https://github.com/erwanBellon/Project-ML-SDM.git\n",
        "%cd /content/Project-ML-SDM\n",
        "!git pull\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Move into the project directory\n",
        "%cd /content/Project-ML-SDM/code\n",
        "print(\"Current working directory:\", Path.cwd())\n",
        "\n",
        "# Define main project dir and outputs\n",
        "PROJECT_ROOT_DIR = Path.cwd().parent\n",
        "OUTPUTS_PATH = PROJECT_ROOT_DIR / \"outputs\"\n",
        "OUTPUTS_PATH.mkdir(parents=True, exist_ok=True)\n",
        "print(\"Outputs will be saved to:\", OUTPUTS_PATH)\n",
        "\n",
        "\n",
        "# Scikit-Learn ≥0.20 is required\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "# TensorFlow ≥2.0 is required\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, Model, Input\n",
        "assert tf.__version__ >= \"2.0\"\n",
        "\n",
        "if not tf.config.list_physical_devices('GPU'):\n",
        "    print(\"No GPU detected. CNNs can be slow without GPU.\")\n",
        "\n",
        "# Common imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "!pip install rasterio\n",
        "import rasterio\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# To make notebook reproducible\n",
        "np.random.seed(123)\n",
        "tf.random.set_seed(123)\n",
        "\n",
        "# For plots\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Load Tensorboard\n",
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(Path.cwd())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwFyFqHTiiaJ",
        "outputId": "ff8e6949-84d5-41ae-ca2b-3991d7964be2"
      },
      "id": "TwFyFqHTiiaJ",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Project-ML-SDM/code\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## I.2 Load the model using a CNN-ANN framework"
      ],
      "metadata": {
        "id": "btSf40XCpxO0"
      },
      "id": "btSf40XCpxO0"
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# Path to your saved model\n",
        "model_path = Path.cwd() /\"../outputs/cnn_bestModel.keras\"\n",
        "\n",
        "# Load model\n",
        "model = load_model(model_path)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 966
        },
        "id": "B68inGVTqAGs",
        "outputId": "80d3267e-e9eb-4068-a9b5-67f3b03541d6"
      },
      "id": "B68inGVTqAGs",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ image_input         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ random_flip         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ image_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mRandomFlip\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ random_zoom         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ random_flip[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mRandomZoom\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ random_translation  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ random_zoom[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mRandomTranslation\u001b[0m) │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m,    │        \u001b[38;5;34m832\u001b[0m │ random_translati… │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m,    │     \u001b[38;5;34m25,632\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m,    │    \u001b[38;5;34m102,528\u001b[0m │ max_pooling2d[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m128\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ table_input         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6272\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_1[\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │         \u001b[38;5;34m48\u001b[0m │ table_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ cnn_output (\u001b[38;5;33mDense\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │    \u001b[38;5;34m200,736\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ table_branch_output │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │        \u001b[38;5;34m136\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ cnn_output[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ table_branch_out… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m1,312\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │        \u001b[38;5;34m264\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ suitability (\u001b[38;5;33mDense\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m9\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ image_input         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ random_flip         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ image_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RandomFlip</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ random_zoom         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ random_flip[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RandomZoom</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ random_translation  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ random_zoom[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RandomTranslation</span>) │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">832</span> │ random_translati… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">25,632</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">102,528</span> │ max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ table_input         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6272</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span> │ table_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ cnn_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │    <span style=\"color: #00af00; text-decoration-color: #00af00\">200,736</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ table_branch_output │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ cnn_output[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ table_branch_out… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,312</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">264</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ suitability (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m994,493\u001b[0m (3.79 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">994,493</span> (3.79 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m331,497\u001b[0m (1.26 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">331,497</span> (1.26 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m662,996\u001b[0m (2.53 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">662,996</span> (2.53 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### I.3 Load image data (and table input) and preprocess the datas\n"
      ],
      "metadata": {
        "id": "yaC6eelXnFMl"
      },
      "id": "yaC6eelXnFMl"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Load images ---\n",
        "presences_path = Path(\"../data/cropped_landcover/presences\")\n",
        "absences_path = Path(\"../data/cropped_landcover/absences\")\n",
        "\n",
        "def load_images_from_folder(folder):\n",
        "    tif_files = list(folder.glob(\"*.tif\"))\n",
        "    images = []\n",
        "    image_indices = []\n",
        "    for tif in tif_files:\n",
        "        with rasterio.open(tif) as src:\n",
        "            img = src.read()\n",
        "            img = np.transpose(img, (1,2,0))\n",
        "            images.append(img.astype(np.float32))\n",
        "        # Extract the line index from the filename (`crop_3000_118.tif`)\n",
        "        idx = int(tif.stem.split(\"_\")[-1])\n",
        "        image_indices.append(idx)\n",
        "    return np.array(images), np.array(image_indices)\n",
        "\n",
        "images_pres, indices_pres = load_images_from_folder(presences_path)\n",
        "images_abs, indices_abs = load_images_from_folder(absences_path)\n",
        "print(f\"Presences: {images_pres.shape}, Absences: {images_abs.shape}\")\n",
        "\n",
        "# Build dataset & labels\n",
        "X = np.concatenate([images_pres, images_abs], axis=0)\n",
        "y = np.concatenate([np.ones(len(images_pres)), np.zeros(len(images_abs))], axis=0).astype(np.int32)\n",
        "image_indices = np.concatenate([indices_pres, indices_abs], axis=0)  # all image row indices\n",
        "\n",
        "# --- Load table data ---\n",
        "rds_path = Path(\"../data/Table_preds/function_3_100.rds\")\n",
        "!pip install pyreadr\n",
        "import pyreadr\n",
        "result = pyreadr.read_r(rds_path)\n",
        "table_df = result[None]  # get DataFrame\n",
        "\n",
        "# Select only the rows corresponding to actual images\n",
        "table_features_all = table_df[['MAP','MAT']].astype(float)\n",
        "table_features = table_features_all.iloc[image_indices].reset_index(drop=True)\n",
        "\n",
        "# Normalize\n",
        "#table_features = (table_features - table_features.min()) / (table_features.max() - table_features.min())\n",
        "#table_features = table_features.to_numpy(dtype=np.float32)\n",
        "\n",
        "\n",
        "X_train, X_temp, table_train, table_temp, y_train, y_temp = train_test_split(\n",
        "    X, table_features, y,\n",
        "    test_size=0.2,\n",
        "    random_state=123,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "X_valid, X_test, table_valid, table_test, y_valid, y_test = train_test_split(\n",
        "    X_temp, table_temp, y_temp,\n",
        "    test_size=0.5,\n",
        "    random_state=123,\n",
        "    stratify=y_temp\n",
        ")\n",
        "\n",
        "# Normalize using TRAIN ONLY\n",
        "\n",
        "min_vals = table_train.min(axis=0)\n",
        "max_vals = table_train.max(axis=0)\n",
        "\n",
        "table_train = (table_train - min_vals) / (max_vals - min_vals)\n",
        "table_valid = (table_valid - min_vals) / (max_vals - min_vals)\n",
        "table_test  = (table_test  - min_vals) / (max_vals - min_vals)\n",
        "\n",
        "table_train = table_train.to_numpy(dtype=np.float32)\n",
        "table_valid = table_valid.to_numpy(dtype=np.float32)\n",
        "table_test  = table_test.to_numpy(dtype=np.float32)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXmsSnh9nOyf",
        "outputId": "2cdb2622-3ef9-43db-8c3f-a8b3b19a719d"
      },
      "id": "qXmsSnh9nOyf",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Presences: (117, 30, 30, 1), Absences: (200, 30, 30, 1)\n",
            "Requirement already satisfied: pyreadr in /usr/local/lib/python3.12/dist-packages (0.5.4)\n",
            "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from pyreadr) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2.0->pyreadr) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2.0->pyreadr) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2.0->pyreadr) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2.0->pyreadr) (2025.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.2.0->pyreadr) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "train_ds = tf.data.Dataset.from_tensor_slices(((X_train, table_train), y_train))\n",
        "valid_ds = tf.data.Dataset.from_tensor_slices(((X_valid, table_valid), y_valid))\n",
        "test_ds  = tf.data.Dataset.from_tensor_slices(((X_test, table_test), y_test))\n",
        "\n",
        "\n",
        "# Add `.name` attribute like TFDS\n",
        "train_ds.name = \"Training\"\n",
        "valid_ds.name = \"Validation\"\n",
        "test_ds.name  = \"Test\""
      ],
      "metadata": {
        "id": "ugWPu3TGnagb"
      },
      "id": "ugWPu3TGnagb",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "def preprocess_multi_inputs(inputs, label):\n",
        "    image, table = inputs\n",
        "    # Convert image to float32 and add channel dimension if needed\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    # Replace Nan (non-forest) with 0s\n",
        "    image = tf.where(tf.math.is_nan(image), 0.0, image)\n",
        "\n",
        "    if len(image.shape) == 3:  # (H,W,C) or (H,W)\n",
        "        image = tf.expand_dims(image, -1)  # ensures (H,W,1)\n",
        "    # Table should already be (batch_size, 2) after batching\n",
        "    table = tf.cast(table, tf.float32)\n",
        "    label = tf.cast(label, tf.float32)\n",
        "    return (image, table), label"
      ],
      "metadata": {
        "id": "kwMhv9mEnes2"
      },
      "id": "kwMhv9mEnes2",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "train_ds = (\n",
        "    tf.data.Dataset.from_tensor_slices(((X_train, table_train), y_train))\n",
        "      .shuffle(1000, reshuffle_each_iteration=True)   # <--- SHUFFLE HERE\n",
        "      .map(preprocess_multi_inputs, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "      .prefetch(tf.data.AUTOTUNE)\n",
        ")\n",
        "valid_ds = (\n",
        "    tf.data.Dataset.from_tensor_slices(((X_valid, table_valid), y_valid))\n",
        "      .map(preprocess_multi_inputs, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "      .prefetch(tf.data.AUTOTUNE)\n",
        ")\n",
        "\n",
        "test_ds = (\n",
        "    tf.data.Dataset.from_tensor_slices(((X_test, table_test), y_test))\n",
        "      .map(preprocess_multi_inputs, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "      .prefetch(tf.data.AUTOTUNE)\n",
        ")\n",
        "\n",
        "# Add `.name` attribute like TFDS\n",
        "train_ds.name = \"Training\"\n",
        "valid_ds.name = \"Validation\"\n",
        "test_ds.name  = \"Test\"\n"
      ],
      "metadata": {
        "id": "d4zlOiMCnhCZ"
      },
      "id": "d4zlOiMCnhCZ",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the test dataset and prepare 15 sample images\n"
      ],
      "metadata": {
        "id": "6nV_tmChrIei"
      },
      "id": "6nV_tmChrIei"
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "sample_images = []\n",
        "sample_tables = []\n",
        "\n",
        "for (img, tab), label in test_ds.take(20):  # to get single samples\n",
        "    # Image preprocessing\n",
        "    img = tf.cast(img, tf.float32)\n",
        "    img = tf.where(tf.math.is_nan(img), 0.0, img)\n",
        "    if len(img.shape) == 2:  # (H,W)\n",
        "        img = tf.expand_dims(img, -1)  # (H,W,1)\n",
        "    sample_images.append(img.numpy())\n",
        "\n",
        "    # Table preprocessing\n",
        "    tab = tf.cast(tab, tf.float32)\n",
        "    sample_tables.append(tab.numpy())\n",
        "\n",
        "# Convert to numpy arrays with batch dimension\n",
        "sample_images = np.stack(sample_images)\n",
        "sample_tables = np.stack(sample_tables)\n",
        "\n",
        "print(\"Sample images shape:\", sample_images.shape)   # (5,H,W,C)\n",
        "print(\"Sample tables shape:\", sample_tables.shape)   # (5,n_features)\n",
        "print(\"Min/Max values:\", img.numpy().min(), img.numpy().max())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-487qDN7rF1l",
        "outputId": "488e008f-2851-4332-9b6d-d3c4b64bba7b"
      },
      "id": "-487qDN7rF1l",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample images shape: (20, 30, 30, 1, 1)\n",
            "Sample tables shape: (20, 2)\n",
            "Min/Max values: 0.0 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## I.4. Looking at the feature maps"
      ],
      "metadata": {
        "id": "PIRpC-JEmOTN"
      },
      "id": "PIRpC-JEmOTN"
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# Print all layers with their output shapes\n",
        "for i, layer in enumerate(model.layers):\n",
        "    try:\n",
        "        shape = layer.output.shape\n",
        "    except AttributeError:\n",
        "        shape = \"N/A\"  # For InputLayer or unusual layers\n",
        "    print(i, layer.name, shape, type(layer))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEXMrSNLmUpK",
        "outputId": "4ee70bc4-19fe-46b8-d020-1082cc5e9996"
      },
      "id": "IEXMrSNLmUpK",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 image_input (None, 30, 30, 1) <class 'keras.src.layers.core.input_layer.InputLayer'>\n",
            "1 random_flip (None, 30, 30, 1) <class 'keras.src.layers.preprocessing.image_preprocessing.random_flip.RandomFlip'>\n",
            "2 random_zoom (None, 30, 30, 1) <class 'keras.src.layers.preprocessing.image_preprocessing.random_zoom.RandomZoom'>\n",
            "3 random_translation (None, 30, 30, 1) <class 'keras.src.layers.preprocessing.image_preprocessing.random_translation.RandomTranslation'>\n",
            "4 conv2d (None, 30, 30, 32) <class 'keras.src.layers.convolutional.conv2d.Conv2D'>\n",
            "5 conv2d_1 (None, 30, 30, 32) <class 'keras.src.layers.convolutional.conv2d.Conv2D'>\n",
            "6 max_pooling2d (None, 15, 15, 32) <class 'keras.src.layers.pooling.max_pooling2d.MaxPooling2D'>\n",
            "7 conv2d_2 (None, 15, 15, 128) <class 'keras.src.layers.convolutional.conv2d.Conv2D'>\n",
            "8 max_pooling2d_1 (None, 7, 7, 128) <class 'keras.src.layers.pooling.max_pooling2d.MaxPooling2D'>\n",
            "9 table_input (None, 2) <class 'keras.src.layers.core.input_layer.InputLayer'>\n",
            "10 flatten (None, 6272) <class 'keras.src.layers.reshaping.flatten.Flatten'>\n",
            "11 dense (None, 16) <class 'keras.src.layers.core.dense.Dense'>\n",
            "12 cnn_output (None, 32) <class 'keras.src.layers.core.dense.Dense'>\n",
            "13 table_branch_output (None, 8) <class 'keras.src.layers.core.dense.Dense'>\n",
            "14 concatenate (None, 40) <class 'keras.src.layers.merging.concatenate.Concatenate'>\n",
            "15 dense_1 (None, 32) <class 'keras.src.layers.core.dense.Dense'>\n",
            "16 dropout (None, 32) <class 'keras.src.layers.regularization.dropout.Dropout'>\n",
            "17 dense_2 (None, 8) <class 'keras.src.layers.core.dense.Dense'>\n",
            "18 suitability (None, 1) <class 'keras.src.layers.core.dense.Dense'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Select the part of the model that outputs features\n",
        "\n",
        "I'm interested at looking at the feature map of the last convolution layer (conv2d_2). So I extract it and output its feature (sub_model)"
      ],
      "metadata": {
        "id": "etxhL-aqPvhn"
      },
      "id": "etxhL-aqPvhn"
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "\n",
        "# Get the conv layer of interest\n",
        "conv_layer = model.get_layer(\"conv2d_2\")\n",
        "print(\"conv layer:\",conv_layer.name, conv_layer.output.shape)\n",
        "\n",
        "# Build sub-model from original model ---\n",
        "# Input = both image and table, output = last conv layer\n",
        "feature_map_model = Model(inputs=model.inputs, outputs=conv_layer.output)\n",
        "\n",
        "# Prepare 15 samples from test dataset ---\n",
        "sample_images = []\n",
        "sample_tables = []\n",
        "\n",
        "for (img, tab), label in test_ds.take(20):  # get single samples\n",
        "    # Image preprocessing\n",
        "    img = tf.cast(img, tf.float32)\n",
        "    img = tf.where(tf.math.is_nan(img), 0.0, img)\n",
        "    if len(img.shape) == 2:  # (H,W)\n",
        "        img = tf.expand_dims(img, -1)  # (H,W,1)\n",
        "    sample_images.append(img.numpy())\n",
        "\n",
        "    # Table preprocessing\n",
        "    tab = tf.cast(tab, tf.float32)\n",
        "    sample_tables.append(tab.numpy())\n",
        "\n",
        "# Convert to numpy arrays with batch dimension\n",
        "sample_images = np.stack(sample_images)\n",
        "sample_tables = np.stack(sample_tables)\n",
        "\n",
        "print(\"Sample images shape:\", sample_images.shape)   # (15,H,W,C)\n",
        "print(\"Sample tables shape:\", sample_tables.shape)   # (15,n_features)\n",
        "print(\"Min/Max values:\", img.numpy().min(), img.numpy().max())\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfJUcDqBraOb",
        "outputId": "80d94e08-2027-4306-a8e7-a8d3c0bafcdc"
      },
      "id": "dfJUcDqBraOb",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conv layer: conv2d_2 (None, 15, 15, 128)\n",
            "Sample images shape: (20, 30, 30, 1, 1)\n",
            "Sample tables shape: (20, 2)\n",
            "Min/Max values: 0.0 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from matplotlib.colors import ListedColormap\n",
        "\n",
        "# Custom colormap: 0 = white, 1 = dark green\n",
        "cmap_img = ListedColormap(['white', 'darkgreen'])\n",
        "\n",
        "# Map label to text\n",
        "label_map = {1: \"Presence\", 0: \"Absence\"}\n",
        "\n",
        "# Directory to save plots in Colab\n",
        "save_dir = Path(\"/content/outputs\")\n",
        "save_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "for i in range(len(sample_images)):\n",
        "    img_batch = sample_images[i:i+1]   # shape (1,H,W,C)\n",
        "    tab_batch = sample_tables[i:i+1]   # shape (1,n_features)\n",
        "    label = y_test[i]                   # true label\n",
        "\n",
        "    # --- Get model prediction ---\n",
        "    pred_prob = model.predict([img_batch, tab_batch], verbose=0)[0,0]\n",
        "\n",
        "    # Predict feature maps\n",
        "    feature_maps = feature_map_model.predict([img_batch, tab_batch], verbose=0)\n",
        "\n",
        "    # Compute mean activation per filter\n",
        "    mean_activation = feature_maps.mean(axis=(1,2))  # shape (1, n_filters)\n",
        "\n",
        "    # Get top 3 activated filters\n",
        "    top3_idx = np.argsort(mean_activation[0])[::-1][:3]\n",
        "\n",
        "    # Plot: original + 3 feature maps\n",
        "    fig, axes = plt.subplots(1, 4, figsize=(16,5))\n",
        "\n",
        "    # Original image with predicted probability\n",
        "    axes[0].imshow(img_batch[0, :, :, 0], cmap=cmap_img, vmin=0, vmax=1)\n",
        "    axes[0].set_title(f\"Original Image\\nTrue: {label_map[label]}, Pred: {pred_prob:.3f}\")\n",
        "    axes[0].axis(\"off\")\n",
        "\n",
        "    # Feature maps\n",
        "    for j, idx in enumerate(top3_idx):\n",
        "        activation = feature_maps[0, :, :, idx]\n",
        "        activation = (activation - activation.min()) / (activation.max() - activation.min() + 1e-8)\n",
        "        im = axes[j+1].imshow(activation, cmap=\"viridis\")\n",
        "        axes[j+1].set_title(f\"Filter {idx}\")\n",
        "        axes[j+1].axis(\"off\")\n",
        "        fig.colorbar(im, ax=axes[j+1], fraction=0.046, pad=0.04)\n",
        "\n",
        "    # Save figure\n",
        "    save_path = save_dir / f\"sample_{i}_{label_map[label]}.png\"\n",
        "    if os.path.isfile(save_path):\n",
        "      os.remove(save_path)\n",
        "      plt.savefig(save_path, bbox_inches=\"tight\")\n",
        "      plt.close(fig)\n",
        "\n",
        "print(f\"Plots saved to {save_dir}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "8U1viZpFyEYq",
        "outputId": "70c59603-e041-4d8e-894c-d08897d21541"
      },
      "id": "8U1viZpFyEYq",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plots saved to /content/outputs\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x500 with 7 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(sample_images)"
      ],
      "metadata": {
        "id": "ExlHAdJP5VcC",
        "outputId": "a39d0954-6a26-4339-d979-ea5376e827f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ExlHAdJP5VcC",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part II: Permutation feature importance (can be ran independently of the rest)"
      ],
      "metadata": {
        "id": "waaDCZx2aOS9"
      },
      "id": "waaDCZx2aOS9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### II.1 Permutation importance for CNN-ANN"
      ],
      "metadata": {
        "id": "jha5GPhKaWm4"
      },
      "id": "jha5GPhKaWm4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Large drop in AUC after shuffling→ feature is important\n",
        "\n",
        "Small or no drop → feature is less important\n",
        "\n",
        "Negative drop → shuffling actually improved performance (can happen due to noise or correlations)"
      ],
      "metadata": {
        "id": "jQPCqB8JlLcm"
      },
      "id": "jQPCqB8JlLcm"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import rasterio\n",
        "import pyreadr\n",
        "\n",
        "#1. Load and preprocess images\n",
        "def load_images_from_folder(folder):\n",
        "    tif_files = sorted(folder.glob(\"*.tif\"))\n",
        "    images = []\n",
        "    image_indices = []\n",
        "    for tif in tif_files:\n",
        "        with rasterio.open(tif) as src:\n",
        "            img = src.read()\n",
        "            img = np.transpose(img, (1, 2, 0))  # (H,W,C)\n",
        "            img = img.astype(np.float32)\n",
        "            img = np.where(np.isnan(img), 0.0, img)  # replace NaNs\n",
        "            if img.ndim == 2:\n",
        "                img = np.expand_dims(img, -1)\n",
        "            images.append(img)\n",
        "        idx = int(tif.stem.split(\"_\")[-1])\n",
        "        image_indices.append(idx)\n",
        "    return np.array(images), np.array(image_indices)\n",
        "\n",
        "presences_path = Path(\"../data/cropped_landcover/presences\")\n",
        "absences_path = Path(\"../data/cropped_landcover/absences\")\n",
        "\n",
        "images_pres, indices_pres = load_images_from_folder(presences_path)\n",
        "images_abs, indices_abs = load_images_from_folder(absences_path)\n",
        "\n",
        "# Labelsadding\n",
        "X = np.concatenate([images_pres, images_abs], axis=0)\n",
        "y = np.concatenate([np.ones(len(images_pres)), np.zeros(len(images_abs))], axis=0)\n",
        "image_indices = np.concatenate([indices_pres, indices_abs], axis=0)\n",
        "\n",
        "# 2. Load table data\n",
        "rds_path = Path(\"../data/Table_preds/function_3_100.rds\")\n",
        "result = pyreadr.read_r(rds_path)\n",
        "table_df = result[None]\n",
        "\n",
        "table_features_all = table_df[['MAP','MAT']].astype(float)\n",
        "table_features = table_features_all.iloc[image_indices].reset_index(drop=True)\n",
        "# normalize\n",
        "#table_features = (table_features - table_features.min()) / (table_features.max() - table_features.min())\n",
        "#table_features = table_features.to_numpy(dtype=np.float32)\n",
        "\n",
        "X_train, X_temp, table_train, table_temp, y_train, y_temp = train_test_split(\n",
        "    X, table_features, y,\n",
        "    test_size=0.2,\n",
        "    random_state=123,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "X_valid, X_test, table_valid, table_test, y_valid, y_test = train_test_split(\n",
        "    X_temp, table_temp, y_temp,\n",
        "    test_size=0.5,\n",
        "    random_state=123,\n",
        "    stratify=y_temp\n",
        ")\n",
        "\n",
        "# Normalize using TRAIN ONLY\n",
        "\n",
        "min_vals = table_train.min(axis=0)\n",
        "max_vals = table_train.max(axis=0)\n",
        "\n",
        "table_train = (table_train - min_vals) / (max_vals - min_vals)\n",
        "table_valid = (table_valid - min_vals) / (max_vals - min_vals)\n",
        "table_test  = (table_test  - min_vals) / (max_vals - min_vals)\n",
        "\n",
        "table_train = table_train.to_numpy(dtype=np.float32)\n",
        "table_valid = table_valid.to_numpy(dtype=np.float32)\n",
        "table_test  = table_test.to_numpy(dtype=np.float32)\n",
        "\n",
        "#  4. Load trained model\n",
        "model1_path = Path.cwd() / \"../outputs/cnn_bestModel.keras\"\n",
        "model1 = load_model(model1_path)\n",
        "\n",
        "\n",
        "#  5. Build inference model\n",
        "from tensorflow import keras\n",
        "\n",
        "model1_path = Path(\"../outputs/cnn_bestModel.keras\")\n",
        "model = keras.models.load_model(model1_path)\n",
        "\n",
        "\n",
        "# 6. Permutation importance\n",
        "# Shuffle the features randomly and evaluate the drop (or delta)in AUC\n",
        "def permutation_importance_multimodal(\n",
        "    model,\n",
        "    images,\n",
        "    table,\n",
        "    y,\n",
        "    table_feature_names,\n",
        "    n_repeats=10,\n",
        "    seed=123\n",
        "):\n",
        "    rng = np.random.default_rng(seed)\n",
        "\n",
        "    images = images.astype(np.float32)\n",
        "    table = table.astype(np.float32)\n",
        "    y = y.astype(np.float32)\n",
        "\n",
        "    # --- Baseline ---\n",
        "    base_pred = model.predict([images, table], verbose=0).ravel()\n",
        "    base_auc = roc_auc_score(y, base_pred)\n",
        "\n",
        "    print(f\"Baseline AUC: {base_auc:.4f}\")\n",
        "\n",
        "    importances = {}\n",
        "\n",
        "    # --- Table features ---\n",
        "    for j, fname in enumerate(table_feature_names):\n",
        "        drops = []\n",
        "        for _ in range(n_repeats):\n",
        "            table_perm = table.copy()\n",
        "            rng.shuffle(table_perm[:, j])\n",
        "            pred = model.predict([images, table_perm], verbose=0).ravel()\n",
        "            auc = roc_auc_score(y, pred)\n",
        "            drops.append(base_auc - auc)\n",
        "\n",
        "        importances[fname] = np.mean(drops)\n",
        "\n",
        "    # --- Image branch (whole-image permutation) ---\n",
        "    drops = []\n",
        "    for _ in range(n_repeats):\n",
        "        idx = rng.permutation(len(images))\n",
        "        images_perm = images[idx]\n",
        "        pred = model.predict([images_perm, table], verbose=0).ravel()\n",
        "        auc = roc_auc_score(y, pred)\n",
        "        drops.append(base_auc - auc)\n",
        "\n",
        "    importances[\"Image\"] = np.mean(drops)\n",
        "\n",
        "    # --- Pretty print ---\n",
        "    print(\"\\nPermutation Importances (ΔAUC):\")\n",
        "    for k, v in sorted(importances.items(), key=lambda x: x[1], reverse=True):\n",
        "        print(f\"{k:10s}: {v:+.4f}\")\n",
        "\n",
        "    return importances, base_auc\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#  7. Compute importance\n",
        "table_feature_names = [\"MAP\", \"MAT\"]\n",
        "\n",
        "importances, base_auc = permutation_importance_multimodal(\n",
        "    model=model,\n",
        "    images=X_test,\n",
        "    table=table_test,\n",
        "    y=y_test,\n",
        "    table_feature_names=table_feature_names,\n",
        "    n_repeats=5\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gK0oxd4VaV9C",
        "outputId": "cc8feda3-e9da-432a-c4a6-b8f217c7c8d9"
      },
      "id": "gK0oxd4VaV9C",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline AUC: 0.9333\n",
            "\n",
            "Permutation Importances (ΔAUC):\n",
            "Image     : +0.2125\n",
            "MAP       : +0.0275\n",
            "MAT       : +0.0258\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### II.2 Permutation for Mimicry ANN"
      ],
      "metadata": {
        "id": "-gcByN5MahFf"
      },
      "id": "-gcByN5MahFf"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from tensorflow.keras.models import load_model\n",
        "import pyreadr\n",
        "\n",
        "# Load table data for ANN-only\n",
        "rds_path = Path(\"../data/Table_preds/function_3_100.rds\")\n",
        "result = pyreadr.read_r(rds_path)\n",
        "table_df = result[None]\n",
        "\n",
        "# Select relevant columns\n",
        "feature_df = table_df[['MAP','MAT','habitat_amount_3000']].astype(float)\n",
        "\n",
        "# Load indices for presences/absences\n",
        "presences_path = Path(\"../data/cropped_landcover/presences\")\n",
        "absences_path = Path(\"../data/cropped_landcover/absences\")\n",
        "\n",
        "def extract_indices(folder):\n",
        "    tif_files = sorted(folder.glob(\"*.tif\"))\n",
        "    indices = []\n",
        "    for tif in tif_files:\n",
        "        idx = int(tif.stem.split(\"_\")[-1])\n",
        "        indices.append(idx)\n",
        "    return np.array(indices)\n",
        "\n",
        "indices_pres = extract_indices(presences_path)\n",
        "indices_abs = extract_indices(absences_path)\n",
        "\n",
        "# Build label vector\n",
        "y = np.concatenate([\n",
        "    np.ones(len(indices_pres)),\n",
        "    np.zeros(len(indices_abs))\n",
        "]).astype(np.float32)\n",
        "\n",
        "# Extract corresponding rows\n",
        "feature_all = feature_df\n",
        "features = feature_all.iloc[np.concatenate([indices_pres, indices_abs])]\n",
        "features = features.reset_index(drop=True)\n",
        "\n",
        "# Train/valid/test split\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    features, y, test_size=0.2, random_state=123, stratify=y\n",
        ")\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.5, random_state=123, stratify=y_temp\n",
        ")\n",
        "\n",
        "\n",
        "# Normalize using TRAIN ONLY\n",
        "\n",
        "min_vals = X_train.min(axis=0)\n",
        "max_vals = X_train.max(axis=0)\n",
        "\n",
        "X_train = (X_train - min_vals) / (max_vals - min_vals)\n",
        "X_valid = (X_valid - min_vals) / (max_vals - min_vals)\n",
        "X_test  = (X_test  - min_vals) / (max_vals - min_vals)\n",
        "\n",
        "# Load ANN-only modeol\n",
        "model2_path = Path.cwd() / \"../outputs//Mirror_ANN_HA_3000_bestModel.keras\"\n",
        "model2 = load_model(model2_path)\n",
        "\n",
        "# Permutation importance for table features\n",
        "\n",
        "def permutation_importance_model2(\n",
        "    model,\n",
        "    table,\n",
        "    y,\n",
        "    feature_names,\n",
        "    n_repeats=10,\n",
        "    seed=42\n",
        "):\n",
        "    rng = np.random.default_rng(seed)\n",
        "\n",
        "    table = np.asarray(table, dtype=np.float32)\n",
        "    y = np.asarray(y, dtype=np.float32)\n",
        "\n",
        "    # --- Baseline ---\n",
        "    base_pred = model.predict(table, verbose=0).ravel()\n",
        "    base_auc = roc_auc_score(y, base_pred)\n",
        "    print(f\"Baseline AUC: {base_auc:.4f}\")\n",
        "\n",
        "    importances = {}\n",
        "\n",
        "    # --- Permute each feature ---\n",
        "    for j, fname in enumerate(feature_names):\n",
        "        drops = []\n",
        "        for _ in range(n_repeats):\n",
        "            table_perm = table.copy()\n",
        "            rng.shuffle(table_perm[:, j])\n",
        "            pred = model.predict(table_perm, verbose=0).ravel()\n",
        "            auc = roc_auc_score(y, pred)\n",
        "            drops.append(base_auc - auc)\n",
        "\n",
        "        importances[fname] = np.mean(drops)\n",
        "\n",
        "    # --- Pretty print ---\n",
        "    print(\"\\nPermutation Feature Importances (ΔAUC):\")\n",
        "    for k, v in sorted(importances.items(), key=lambda x: x[1], reverse=True):\n",
        "        print(f\"{k:22s}: {v:+.4f}\")\n",
        "\n",
        "    return importances, base_auc\n",
        "\n",
        "feature_names = [\"MAP\", \"MAT\", \"habitat_amount_3000\"]\n",
        "\n",
        "importances, base_auc = permutation_importance_model2(\n",
        "    model=model2,\n",
        "    table=X_test,\n",
        "    y=y_test,\n",
        "    feature_names=feature_names,\n",
        "    n_repeats=5\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYc6Z3hJjLup",
        "outputId": "4c916584-4e64-4ce2-f290-3581ebb62a45"
      },
      "id": "iYc6Z3hJjLup",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline AUC: 0.8417\n",
            "\n",
            "Permutation Feature Importances (ΔAUC):\n",
            "habitat_amount_3000   : +0.0642\n",
            "MAT                   : +0.0583\n",
            "MAP                   : +0.0425\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### II.3 Permutation importance for optimised ANN"
      ],
      "metadata": {
        "id": "A-fOodxhOemW"
      },
      "id": "A-fOodxhOemW"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from tensorflow.keras.models import load_model\n",
        "import pyreadr\n",
        "\n",
        "# Load table data for ANN-only\n",
        "rds_path = Path(\"../data/Table_preds/function_3_100.rds\")\n",
        "result = pyreadr.read_r(rds_path)\n",
        "table_df = result[None]\n",
        "\n",
        "# Select relevant columns\n",
        "feature_df = table_df[['MAP','MAT','habitat_amount_3000']].astype(float)\n",
        "\n",
        "# Load indices for presences/absences\n",
        "presences_path = Path(\"../data/cropped_landcover/presences\")\n",
        "absences_path = Path(\"../data/cropped_landcover/absences\")\n",
        "\n",
        "def extract_indices(folder):\n",
        "    tif_files = sorted(folder.glob(\"*.tif\"))\n",
        "    indices = []\n",
        "    for tif in tif_files:\n",
        "        idx = int(tif.stem.split(\"_\")[-1])\n",
        "        indices.append(idx)\n",
        "    return np.array(indices)\n",
        "\n",
        "indices_pres = extract_indices(presences_path)\n",
        "indices_abs = extract_indices(absences_path)\n",
        "\n",
        "# Build label vector\n",
        "y = np.concatenate([\n",
        "    np.ones(len(indices_pres)),\n",
        "    np.zeros(len(indices_abs))\n",
        "]).astype(np.float32)\n",
        "\n",
        "# Extract corresponding rows\n",
        "feature_all = feature_df\n",
        "features = feature_all.iloc[np.concatenate([indices_pres, indices_abs])]\n",
        "features = features.reset_index(drop=True)\n",
        "\n",
        "# Train/valid/test split\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    features, y, test_size=0.2, random_state=123, stratify=y\n",
        ")\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.5, random_state=123, stratify=y_temp\n",
        ")\n",
        "\n",
        "\n",
        "# Normalize using TRAIN ONLY\n",
        "\n",
        "min_vals = X_train.min(axis=0)\n",
        "max_vals = X_train.max(axis=0)\n",
        "\n",
        "X_train = (X_train - min_vals) / (max_vals - min_vals)\n",
        "X_valid = (X_valid - min_vals) / (max_vals - min_vals)\n",
        "X_test  = (X_test  - min_vals) / (max_vals - min_vals)\n",
        "\n",
        "# Load optimised ANN-only modeol\n",
        "model3_path = Path.cwd() / \"../outputs/Optimised_ANN_HA_3000_bestModel.keras\"\n",
        "model3 = load_model(model3_path)\n",
        "\n",
        "# Permutation importance for table features\n",
        "\n",
        "def permutation_importance_model3(\n",
        "    model,\n",
        "    table,\n",
        "    y,\n",
        "    feature_names,\n",
        "    n_repeats=10,\n",
        "    seed=123\n",
        "):\n",
        "    rng = np.random.default_rng(seed)\n",
        "\n",
        "    table = np.asarray(table, dtype=np.float32)\n",
        "    y = np.asarray(y, dtype=np.float32)\n",
        "\n",
        "    # --- Baseline ---\n",
        "    base_pred = model.predict(table, verbose=0).ravel()\n",
        "    base_auc = roc_auc_score(y, base_pred)\n",
        "    print(f\"Baseline AUC: {base_auc:.4f}\")\n",
        "\n",
        "    importances = {}\n",
        "\n",
        "    # --- Permute each feature ---\n",
        "    for j, fname in enumerate(feature_names):\n",
        "        drops = []\n",
        "        for _ in range(n_repeats):\n",
        "            table_perm = table.copy()\n",
        "            rng.shuffle(table_perm[:, j])\n",
        "            pred = model.predict(table_perm, verbose=0).ravel()\n",
        "            auc = roc_auc_score(y, pred)\n",
        "            drops.append(base_auc - auc)\n",
        "\n",
        "        importances[fname] = np.mean(drops)\n",
        "\n",
        "    # --- Pretty print ---\n",
        "    print(\"\\nPermutation Feature Importances (ΔAUC):\")\n",
        "    for k, v in sorted(importances.items(), key=lambda x: x[1], reverse=True):\n",
        "        print(f\"{k:22s}: {v:+.4f}\")\n",
        "\n",
        "    return importances, base_auc\n",
        "\n",
        "feature_names = [\"MAP\", \"MAT\", \"habitat_amount_3000\"]\n",
        "\n",
        "importances, base_auc = permutation_importance_model3(\n",
        "    model=model3,\n",
        "    table=X_test,\n",
        "    y=y_test,\n",
        "    feature_names=feature_names,\n",
        "    n_repeats=5\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3debe13c-9046-4ea7-c1eb-af0852162930",
        "id": "8mszaif8QbwK"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline AUC: 0.8583\n",
            "\n",
            "Permutation Feature Importances (ΔAUC):\n",
            "MAP                   : +0.1462\n",
            "MAT                   : +0.0642\n",
            "habitat_amount_3000   : +0.0338\n"
          ]
        }
      ],
      "id": "8mszaif8QbwK"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### II.4 Logistic regression model"
      ],
      "metadata": {
        "id": "S4B6oCjWRQFy"
      },
      "id": "S4B6oCjWRQFy"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from joblib import load\n",
        "import pyreadr\n",
        "\n",
        "# 1. Load table data\n",
        "rds_path = Path(\"../data/Table_preds/function_3_100.rds\")\n",
        "result = pyreadr.read_r(rds_path)\n",
        "table_df = result[None]\n",
        "\n",
        "feature_df = table_df[['MAP', 'MAT', 'habitat_amount_3000']].astype(float)\n",
        "\n",
        "# 2. Load presence / absence indices (ORDERED)\n",
        "presences_path = Path(\"../data/cropped_landcover/presences\")\n",
        "absences_path = Path(\"../data/cropped_landcover/absences\")\n",
        "\n",
        "def extract_indices(folder):\n",
        "    tif_files = sorted(folder.glob(\"*.tif\"))\n",
        "    return np.array([int(t.stem.split(\"_\")[-1]) for t in tif_files])\n",
        "\n",
        "indices_pres = extract_indices(presences_path)\n",
        "indices_abs  = extract_indices(absences_path)\n",
        "\n",
        "# 3. Labels + features\n",
        "y = np.concatenate([\n",
        "    np.ones(len(indices_pres)),\n",
        "    np.zeros(len(indices_abs))\n",
        "]).astype(np.float32)\n",
        "\n",
        "features = feature_df.iloc[np.concatenate([indices_pres, indices_abs])]\n",
        "features = features.reset_index(drop=True)\n",
        "\n",
        "# 4. Train / valid / test split\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    features, y, test_size=0.2, random_state=123, stratify=y\n",
        ")\n",
        "\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.5, random_state=123, stratify=y_temp\n",
        ")\n",
        "\n",
        "# 5. Normalize using TRAIN ONLY\n",
        "min_vals = X_train.min(axis=0)\n",
        "max_vals = X_train.max(axis=0)\n",
        "\n",
        "X_train = ((X_train - min_vals) / (max_vals - min_vals)).to_numpy(np.float32)\n",
        "X_valid = ((X_valid - min_vals) / (max_vals - min_vals)).to_numpy(np.float32)\n",
        "X_test  = ((X_test  - min_vals) / (max_vals - min_vals)).to_numpy(np.float32)\n",
        "\n",
        "# 6. Load trained logistic regression\n",
        "model_path = Path.cwd() / \"../outputs/LogReg_HA_3000_model.joblib\"\n",
        "maxent = load(model_path)\n",
        "\n",
        "# 7. Permutation importance\n",
        "def permutation_importance_logreg(\n",
        "    model,\n",
        "    X,\n",
        "    y,\n",
        "    feature_names,\n",
        "    n_repeats=10,\n",
        "    seed=123\n",
        "):\n",
        "    rng = np.random.default_rng(seed)\n",
        "\n",
        "    X = np.asarray(X, dtype=np.float32)\n",
        "    y = np.asarray(y, dtype=np.float32)\n",
        "\n",
        "    # --- Baseline ---\n",
        "    base_probs = model.predict_proba(X)[:, 1]\n",
        "    base_auc = roc_auc_score(y, base_probs)\n",
        "    print(f\"Baseline AUC: {base_auc:.4f}\")\n",
        "\n",
        "    importances = {}\n",
        "\n",
        "    # --- Permute each feature ---\n",
        "    for j, fname in enumerate(feature_names):\n",
        "        drops = []\n",
        "        for _ in range(n_repeats):\n",
        "            X_perm = X.copy()\n",
        "            rng.shuffle(X_perm[:, j])\n",
        "\n",
        "            probs = model.predict_proba(X_perm)[:, 1]\n",
        "            auc = roc_auc_score(y, probs)\n",
        "\n",
        "            drops.append(base_auc - auc)\n",
        "\n",
        "        importances[fname] = np.mean(drops)\n",
        "\n",
        "    # --- Pretty print ---\n",
        "    print(\"\\nPermutation Feature Importances (ΔAUC):\")\n",
        "    for k, v in sorted(importances.items(), key=lambda x: x[1], reverse=True):\n",
        "        print(f\"{k:22s}: {v:+.4f}\")\n",
        "\n",
        "    return importances, base_auc\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 8. Run importance on test set\n",
        "# --------------------------------------------------\n",
        "feature_names = [\"MAP\", \"MAT\", \"habitat_amount_3000\"]\n",
        "\n",
        "importances, base_auc = permutation_importance_logreg(\n",
        "    model=maxent,\n",
        "    X=X_test,\n",
        "    y=y_test,\n",
        "    feature_names=feature_names,\n",
        "    n_repeats=5\n",
        ")\n"
      ],
      "metadata": {
        "id": "Rj8okvola6Z1",
        "outputId": "79a77a5c-3dc1-4a0c-f303-1766d6f3569a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Rj8okvola6Z1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline AUC: 0.8417\n",
            "\n",
            "Permutation Feature Importances (ΔAUC):\n",
            "MAT                   : +0.1317\n",
            "MAP                   : +0.0942\n",
            "habitat_amount_3000   : +0.0317\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}